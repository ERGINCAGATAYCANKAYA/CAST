% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/uncertainty.R
\name{uncertainty}
\alias{uncertainty}
\title{Estimate uncertainty of spatial prediction models}
\usage{
uncertainty(train, predictors, weights = NA, model = NA,
  variables = "all")
}
\arguments{
\item{train}{a data.frame containing the data used for model training}

\item{predictors}{A RasterStack, RasterBrick or data.frame containing the data
the model was meant to make predictions for.}

\item{weights}{A data.frame containing weights for each variable}

\item{model}{A caret model used to extract weights from (based on variable importance)}

\item{variables}{character vector of predictor variables. if "all" then all variables
of the train dataset are used.}
}
\value{
A RasterLayer or data.frame containing the scaled distance to the
nearest training data point in the predictor space.
}
\description{
this function estimates uncertainty of spatial prediction models by
considering the distance of new data (i.e. a Raster Stack of spatial predictors
used in the models) in the predictor variable space to the data used for model
training. Predictors can be weighted in the ideal case based on the internal
variable importance of the machine learning algorithm used for model training.
}
\details{
Results range from 0 to 1 with 0 has only a short distance to the nearest
training point and predictions can be considered very certain. 1 has the largest
distance to the training data, hence predictions are more uncertain.
Or explained in an other way: If a location is very similar to the properties
of the training data it will have a low uncertainty while locations that are
very different in its properties will have a high uncertainty.
}
\examples{
library(sf)
library(raster)
library(caret)
library(lubridate)

# prepare sample data:
dat <- get(load(system.file("extdata","Cookfarm.RData",package="CAST")))
studyArea <- stack(system.file("extdata","predictors_2012-03-25.grd",package="CAST"))
variables <- c("DEM","Easting","Northing")
trainDat <- aggregate(dat[,c("VW",variables)],by=list(as.character(dat$SOURCEID)),mean)

# visualize data spatially:
plot(studyArea[[1]])
pts <- st_as_sf(trainDat,coords=c("Easting","Northing"))
plot(pts["Group.1"],add=TRUE,col="black")

# first calculate uncertainty based on a set of variables with equal weights:
plot(uncertainty(trainDat,studyArea,variables=variables))
plot(pts["Group.1"],add=TRUE,col="black") #add training data to plot

# or weight variables based on variable improtance from a trained model:
set.seed(100)
model <- train(trainDat[,which(names(trainDat)\%in\%variables)],
trainDat$VW,method="rf",importance=TRUE,tuneLength=1)
plot(varImp(model))
# note that coordinates are the major predictors here, so uncertainty becomes higher
# when moving away from the training data:
plot(uncertainty(trainDat,studyArea,model=model,variables=variables))
plot(pts["Group.1"],add=TRUE,col="black") #add training data to plot


}
\author{
Hanna Meyer
}
