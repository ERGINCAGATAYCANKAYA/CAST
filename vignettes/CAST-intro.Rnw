%\VignetteIndexEntry{Spatio-temporal predictive modelling with ``caret`` and ``CAST``}

\documentclass{article}
\usepackage[ansinew]{inputenc}
\usepackage{Sweave}
\usepackage[sort]{natbib}
\usepackage[
  pdftitle={Spatio-temporal predictive modelling with ``caret`` and ``CAST``},
  pdfauthor={Hanna Meyer},
  pdfsubject={},
  bookmarksopen=true,
  colorlinks,
  linkcolor=blue,
  citecolor=blue,
  pdfstartview=FitH,
  pdfkeywords={CAST, caret, spatio-temporal, overfitting, feature selection, spatial autocorrelation, model validation},
  urlcolor=blue%
]{hyperref}
\usepackage[dvipsnames]{xcolor}
\usepackage{xspace}

\usepackage{geometry}
\geometry{a4paper,left=3.7cm,right=3.7cm, top=3.5cm, bottom=3.5cm}

\title{Spatio-temporal predictive modelling with ``caret`` and ``CAST``}
\author{Hanna Meyer}

\newcommand{\CAST}{\textsf{CAST}\xspace}

\newenvironment{framed}
  {
    \par\noindent
    \makebox[\linewidth]{\textcolor{gray}{\rule{\textwidth}{0.4pt}}}
    \color{darkgray}
  }{
      \textcolor{gray}{\rule{\textwidth}{0.4pt}}\normalcolor}

\begin{document}
\SweaveOpts{concordance=TRUE}


\maketitle
\tableofcontents
\newpage

<<echo=false>>=
options(width=70)
@

\section{Introduction}
\subsection{Background}
One key task in environmental science is obtaining information of environmental variables in space or in space and time, usually based on limited field data. In that respect, machine learning algorithms have been proven
to be an important tool to learn patterns in nonlinear and complex systems.
However, standard machine learning applications are not suitable for spatio-temporal data, as they usually ignore the spatio-temporal dependencies in the data. This becomes problematic in (at least) two aspects of predictive modelling: Overfitting during model setup as well as objective error assessment. To approach these problems, CAST supports the well-known caret package to allow accounting for spatio-temporal dependencies in prediction tasks.

This tutorial shows how to set up a spatio-temporal prediction model that includes objective and reliable error estimation. It further shows how spatio-temporal overfitting can be detected by comparison between validation strategies. It will be shown that certain variables are responsible for the problem of overfitting due to spatio-temporal autocorrelation patterns. Therefore, this tutorial also shows how to automatically exclude variables that lead to overfitting with the aim to improve the spatio-temporal prediction model.

In order to follow this tutorial, I assume that the reader is familiar with the basics of predictive modelling nicely explained in \citet{Kuhn2013} as well as machine learning applications via the caret package.


\subsection{How to start}
To work with the tutorial, first install the CAST package and load the library:

<<echo=TRUE,eval=TRUE,results=hide>>=
#install.packages("CAST")
library(CAST)
@

If you need help, see

<<echo=TRUE,eval=FALSE,results=hide>>=
help(CAST)
@


\section{Example of a typical spatio-temporal prediction task}

Let's consider the following prediction task: We have a set of data loggers distributed over a farm, and we want to map soil moisture, based on a set of spatial and temporal predictor variables. Random Forests are used as a machine learning algorithm in this tutorial.

\subsection{Description of the example dataset}
To do so, we will work with the cookfarm dataset, described in e.g. \citet{Gasch2015} and available via the GSIF package. The dataset included in CAST is a re-structured dataset which was used for the analysis in \citet{Meyer2018}.


<<echo=TRUE,eval=TRUE>>=
data <- get(load(system.file("extdata","Cookfarm.RData",package="CAST")))
head(data)
@

I want to point out on the following information of this dataset: The SOURCEID represents the ID for the data logger, VW is soil moisture which is our response variable, Easting and Northing are the coordinates of the data loggers, altitude indicates the depth of the soil in which was measured, and the remaining columns represent different potential predictor variables which are ain related (e.g. DEM), vegetation indices (e.g. NDVI), soil properties (e.g. BLD) or climate-related predictors (e.g. Precip$\_$wrcc).
See \citet{Gasch2015} for further description on the dataset.

To get an impression on the spatial properties of the dataset, Let's have a look on the spatial distribution of the data loggers:

<<echo=TRUE,eval=TRUE, fig=TRUE>>=
library(sp)
data_sp <- unique(data[,c("SOURCEID","Easting","Northing")])
coordinates(data_sp) <- ~Easting+Northing
proj4string(data_sp) <-  "+proj=utm +zone=11 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0"
plot(data_sp,axes=TRUE)
@


We see that the data are taken at 42 locations (SOURCEID) over the field. If we have a closer look on the temporal information in the data, we see that the loggers recorded data between 2007 and 2013. The data are given here on a daily basis.


\subsection{Data subsetting}
To reduce the data to an amount that can be handeld in a tutorial, let's restrict the data to the depth -0.3 and to two weeks of the year 2012 and get an overview about the time series.


<<echo=TRUE,eval=TRUE,fig=TRUE>>=
library(lubridate)
library(ggplot2)
trainDat <- data[data$altitude==-0.3&year(data$Date)==2012&week(data$Date)%in%c(13:14),]
ggplot(data = trainDat, aes(x=Date, y=VW)) + geom_line(aes(colour=SOURCEID))
@

What we can see is that (as expected) each logger location has a unique time series of soil moisture.
In the following we will use this subset of the cookfarm data as an example to predict soil moisture with (and without) consideration of the spatio-temporal dependencies.


\section {Model training and prediction}
To start with, lets use this dataset to create a "default" Random Forest model that predicts soil moisture based on a hand full of predictor variables.
To keep computation time at a minimum, we don't consider hyperparameter tuning (hence we set tuneLength to 1) which is reasonable as random forest comparably insensitive to tuning.

<<echo=TRUE,eval=TRUE>>=
library(caret)
predictors <- c("DEM","BLD","TWI","Precip_cum","cday",
                "MaxT_wrcc","Precip_wrcc",#"Bt",
                #"MinT_wrcc",
                "Northing","Easting","NDRE.M")
set.seed(10)
model <- train(trainDat[,predictors],trainDat$VW,
               method="rf",tuneLength=1,importance=TRUE,
               trControl=trainControl(method="cv",number=5))
@


Based on the trained model we can make spatial predictions of soil moisture. To do this we load a RasterStack that contains spatial data of all predictor variables for the day 25th of March 2012. We then apply the trained model on this data set.


<<echo=TRUE,eval=TRUE,fig=TRUE>>=
library(raster)
predictors_sp <- stack(system.file("extdata","predictors_2012-03-25.grd",package="CAST"))
prediction <- predict(predictors_sp,model)
spplot(prediction)
@

The result is a spatially comprehensive map of soil moisture for this day.
We see that simply creating a map using ML is an easy task, however accurately measuring its performance is less simple. Though the map looks good on a first sight we now have to follow the question of how accurate this map is, hence we need to ask how well the model is able to map soil moisture.

From a visible inspection it is noticeable that the model produces a strange linear features at the eastern side of the farm which looks suspicious. But let's come back to this later and first focus on a statistical validation of the models.

\section {Cross validation strategies for spatio-temporal data}
Amongst validation strategies, k-fold cross validation (CV) is popular to estimate the performance of the model in view to data that have not been used for model training. During CV, models are repeatedly trained (k models) and in each model run, the data of one fold are put to the side and are not used for model training but for model validation. In this way, the performance of the model can be estimated using data that have not been included in the model training.

\subsection{The Standard approach: Random k-fold CV}

In the example above we used a random k-fold CV as indicated in caret's trainControl argument. More specifically, we used a random 5-fold CV. Hence, the data points in our dataset are RANDOMLY split into 5 folds.
To assess the performance of the model let's have a look on the output of the Random CV:


<<echo=TRUE,eval=TRUE>>=
model
@


We see that soil moisture could be modelled with an $R^2$ of more than 0.97 which indicates a nearly perfect fit of the data. Sounds good, but unfortunately, the random k fold CV does not give us a good indication for the model performance. Random k-fold CV means that each of the five folds (with the highest certainty) contains data points from each data logger. Therefore, a random CV cannot indicate the ability of the model to make predictions beyond the location of the training data (i.e. to map soil moisture). Since our aim is to map soil moisture, we rather need to perform a target-oriented validation which validates the model in view to spatial mapping.


\subsection {Target-oriented validation}

We are not interested in the model performance in view to random subsets of our data loggers, but we need to know how well the model is able to make predictions for areas without data loggers.
To find this out, we need to repeatedly leave the complete time series of one or more data loggers out and use them as test data during CV.

To do this we first need to create meaningful folds rather than random folds. CASTS's function "CreateSpaceTimeFolds" is designed to provide index arguments used by caret's trainControl. The index defines which data points are used for model training during each model run and reversely defines which data points are held back. Hence, using the index argument we can account for the dependencies in the data by leaving the complete data from one or more data loggers out (LLO CV), from one or more time steps out (LTO CV) or from data loggers and time steps out (LLTO CV). In this example we're focusing on LLO CV, therefore we use the column "SOURCEID" to define the location of a data logger and split the data into folds using this information.
Analogous to the random CV, in this example we split the data into five folds, hence five model runs are performed each leaving one third of all data loggers out for validation.



<<echo=TRUE,eval=TRUE>>=
set.seed(10)
indices <- CreateSpacetimeFolds(trainDat,spacevar = "SOURCEID",
                                k=5)
set.seed(10)
model_LLO <- train(trainDat[,predictors],trainDat$VW,
                   method="rf",tuneLength=1, importance=TRUE,
                   trControl=trainControl(method="cv",index = indices$index))
model_LLO
@


By inspecting the output of the model, we see that in view to new locations, the $R^2$ is only 0.24 so the performance is much much lower than expected from the random CV ($R^2$ = 0.97).
Apparently, there is considerable overfitting in the model, causing a good random performance but a poor performance in view to new locations. This might partly be attributed to the choice of variables where we must suspect that certain variables are misinterpreted by the model \citep[see][]{Meyer2018}.

Let's have a look at the variable importance ranking of Random Forest and see if we find something suspicious:

<<echo=TRUE,eval=TRUE, fig=TRUE>>=
plot(varImp(model_LLO))
@

The importance ranking indicates that "Easting" is an important variable. Keep in mind that we observed inappropriate linear features in the predicted map. Apparently the model assigns a high importance to this variable which causes a high random CV performance. At the same time the model fails in the prediction on new locations.

Assuming that certain variables are misinterpreted by the algorithm we should produce a higher LLO performance when these variables are removed.
Let's see if this is true...


\section{Removing variables that cause overfitting}
CAST's forward feature selection (ffs) selects variables that make in view to the selected CV method and excludes those which are counterproductive in view to the selected CV method.
When we use LLO as CV method, ffs selects variables that lead in combination to the highest LLO performance (i.e. the best spatial model). All variables that have no spatial meaning or are even counterproductive won't improve or even reduce the LLO performance and are therefore excluded from the model by the ffs.

ffs is doing this job by first training models using all possible pairs of two predictor variables. The best model of these initial models is kept. On the basis of this best model the predictor variables are iteratively increased and each of the remaining variables is tested for its improvement of the currently best model. The process stops if none of the remaining variables increases the model performance when added to the current best model.

So let's run the ffs on our case study using $R^2$ as a metric to select the optimal variables. This process will take 1-2 minutes...

<<echo=TRUE,eval=TRUE>>=
set.seed(10)
ffsmodel_LLO <- ffs(trainDat[,predictors],trainDat$VW,metric="Rsquared",
                    method="rf",tuneLength=1, verbose=FALSE,
                    trControl=trainControl(method="cv",index = indices$index))
ffsmodel_LLO
ffsmodel_LLO$selectedvars
@

Using the ffs with LLO CV, the $R^2$could be increased from 0.24 to 0.36. The variables that are used for this model are "TWI","NDRE.M","BLD" and "cday".
%since small dataset variable and changes with seed however temporally static variables (e.g. coordinates, elevation,...) and variable cday should never occur together because they allow the algorithm to access the time series of each data logger which causes overfitting.

Using the plot$\_$ffs function we can visualize how the performance of the model changed depending on the variables being used:


<<echo=TRUE,eval=TRUE, fig=TRUE>>=
plot_ffs(ffsmodel_LLO)
@

See that the two first chosen variables led to a $R^2$ of slightly below 0.35. Using the third and forth variable could slightly increase the $R^2$. Any fifth variable could not improve the LLO performance.
Note that the $R^2$ features a high standard deviation regardless of the variables being used. This is due to the small subset of the dataset that was used which cannot lead to robust results.

What effect does the new model has on the spatial representation of soil moisture?

<<echo=TRUE,eval=TRUE, fig=TRUE>>=
prediction_ffs <- predict(predictors_sp,ffsmodel_LLO)
spplot(prediction_ffs)
@

We see that the variable selection does not only have an effect on the statistical performance but also spatial patterns change considerably. It is of note that the linear feature is not any more in the resulting soil moisture map.


\section {Conclusions}
To conclude, the tutorial has shown how CAST can be used to facilitate target-oriented CV on spatial and spatio-temporal data which is crucial to obtain meaningful validation results. Using the ffs in conjunction with target-oriented validation, variables could be excluded that are counterproductive in view to the target-orineted performance due to misinterpretations by the algorithm. ffs therefore helps to select the ideal set of predictor variables for spatio-temporal prediction tasks and gives objective error estimates.

\section {Final notes}
The intention of this tutorial is to describe the motivation that led to the development of CAST as well as its functionality. Priority is not on modelling soil moisture of the cookfarm in the best possible way but to provide an example for the motivation and functionality of CAST that can run within a few minutes. Hence, only a very small subset of the entire cookfarm dataset was used. Keep in mind that due to the small subset the example is not robust and quite different results might be obtained depending on small changes in the settings.

The intention of showing the motivation of CAST is also the reason why the coordinates are used here as predictor variables. Though coordinates are used as predictors in quite some scientific studies they rather provide here an extreme example of how misleading variables can lead to overfitting.

\clearpage
\phantomsection
\addcontentsline{toc}{section}{References}
\bibliography{CAST}\bibliographystyle{plainnat}

\end{document}
